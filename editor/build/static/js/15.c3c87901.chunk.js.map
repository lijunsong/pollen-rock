{"version":3,"sources":["../node_modules/codemirror/mode/coffeescript/coffeescript.js"],"names":["CodeMirror","defineMode","conf","parserConf","ERRORCLASS","wordRegexp","words","RegExp","join","operators","delimiters","identifiers","atProp","wordOperators","indentKeywords","keywords","concat","stringPrefixes","regexPrefixes","constants","tokenBase","stream","state","sol","scope","align","scopeOffset","offset","eatSpace","lineOffset","indentation","type","dedent","ch","peek","match","skipToEnd","tokenize","longComment","floatLiteral","backUp","intLiteral","tokenFactory","current","prop","next","delimiter","singleline","outclass","eol","eatWhile","eat","singleLineStringErrors","indent","alignOffset","prev","indentUnit","column","length","_indent","matched","external","startState","basecolumn","token","fillAlign","style","delimiter_index","indexOf","slice","exec","tokenLexer","text","closer","charAt","closes","lineComment","fold","defineMIME","mod","__webpack_require__"],"mappings":"8EAYC,SAAAA,GACD,aAEAA,EAAAC,WAAA,wBAAAC,EAAAC,GACA,IAAAC,EAAA,QAEA,SAAAC,EAAAC,GACA,WAAAC,OAAA,MAAAD,EAAAE,KAAA,gBAGA,IAAAC,EAAA,mHACAC,EAAA,gCACAC,EAAA,4BACAC,EAAA,6BACAC,EAAAR,EAAA,2DACAS,EAAA,qFAEAC,EAAAV,EAAAS,EAAAE,OADA,iIAEAF,EAAAT,EAAAS,GACA,IAAAG,EAAA,sBACAC,EAAA,cAEAC,EAAAd,EADA,4EAGA,SAAAe,EAAAC,EAAAC,GAEA,GAAAD,EAAAE,MAAA,CACA,OAAAD,EAAAE,MAAAC,QAAAH,EAAAE,MAAAC,OAAA,GACA,IAAAC,EAAAJ,EAAAE,MAAAG,OAEA,GAAAN,EAAAO,WAAA,CACA,IAAAC,EAAAR,EAAAS,cAEA,OAAAD,EAAAH,GAAA,UAAAJ,EAAAE,MAAAO,KACA,SACWF,EAAAH,EACX,SAGA,KAEAA,EAAA,GACAM,EAAAX,EAAAC,GAKA,GAAAD,EAAAO,WACA,YAGA,IAAAK,EAAAZ,EAAAa,OAEA,GAAAb,EAAAc,MAAA,QAEA,OADAd,EAAAe,YACA,UAIA,GAAAf,EAAAc,MAAA,OAEA,OADAb,EAAAe,SAAAC,EACAhB,EAAAe,SAAAhB,EAAAC,GAIA,SAAAW,EAEA,OADAZ,EAAAe,YACA,UAIA,GAAAf,EAAAc,MAAA,kBACA,IAAAI,GAAA,EAcA,GAZAlB,EAAAc,MAAA,gCACAI,GAAA,GAGAlB,EAAAc,MAAA,iBACAI,GAAA,GAGAlB,EAAAc,MAAA,cACAI,GAAA,GAGAA,EAMA,MAJA,KAAAlB,EAAAa,QACAb,EAAAmB,OAAA,GAGA,SAIA,IAAAC,GAAA,EAgBA,GAdApB,EAAAc,MAAA,qBACAM,GAAA,GAIApB,EAAAc,MAAA,+BACAM,GAAA,GAIApB,EAAAc,MAAA,oBACAM,GAAA,GAGAA,EACA,eAKA,GAAApB,EAAAc,MAAAlB,GAEA,OADAK,EAAAe,SAAAK,EAAArB,EAAAsB,WAAA,YACArB,EAAAe,SAAAhB,EAAAC,GAIA,GAAAD,EAAAc,MAAAjB,GAAA,CACA,QAAAG,EAAAsB,WAAAtB,EAAAc,MAAA,YAGA,OADAb,EAAAe,SAAAK,EAAArB,EAAAsB,WAAA,cACArB,EAAAe,SAAAhB,EAAAC,GAEAD,EAAAmB,OAAA,GAKA,OAAAnB,EAAAc,MAAA1B,IAAAY,EAAAc,MAAAtB,GACA,WAGAQ,EAAAc,MAAAzB,GACA,cAGAW,EAAAc,MAAAhB,GACA,OAGAE,EAAAc,MAAAvB,IAAAU,EAAAsB,MAAAvB,EAAAc,MAAAxB,GACA,WAGAU,EAAAc,MAAApB,GACA,UAGAM,EAAAc,MAAAxB,GACA,YAIAU,EAAAwB,OACAzC,GAGA,SAAAsC,EAAAI,EAAAC,EAAAC,GACA,gBAAA3B,EAAAC,GACA,MAAAD,EAAA4B,OAGA,GAFA5B,EAAA6B,SAAA,aAEA7B,EAAA8B,IAAA,OAGA,GAFA9B,EAAAwB,OAEAE,GAAA1B,EAAA4B,MACA,OAAAD,MAEW,IAAA3B,EAAAc,MAAAW,GAEX,OADAxB,EAAAe,SAAAjB,EACA4B,EAEA3B,EAAA8B,IAAA,UAYA,OARAJ,IACA5C,EAAAiD,uBACAJ,EAAA5C,EAEAkB,EAAAe,SAAAjB,GAIA4B,GAIA,SAAAV,EAAAjB,EAAAC,GACA,MAAAD,EAAA4B,OAAA,CAGA,GAFA5B,EAAA6B,SAAA,QAEA7B,EAAAc,MAAA,QACAb,EAAAe,SAAAjB,EACA,MAGAC,EAAA6B,SAAA,KAGA,gBAGA,SAAAG,EAAAhC,EAAAC,EAAAS,GACAA,KAAA,SAKA,IAJA,IAAAJ,EAAA,EACAF,GAAA,EACA6B,EAAA,KAEA9B,EAAAF,EAAAE,MAAmCA,EAAOA,IAAA+B,KAC1C,cAAA/B,EAAAO,MAAA,KAAAP,EAAAO,KAAuD,CACvDJ,EAAAH,EAAAG,OAAAzB,EAAAsD,WACA,MAIA,WAAAzB,GACAN,EAAA,KACA6B,EAAAjC,EAAAoC,SAAApC,EAAAsB,UAAAe,QACOpC,EAAAE,MAAAC,QACPH,EAAAE,MAAAC,OAAA,GAGAH,EAAAE,MAAA,CACAG,SACAI,OACAwB,KAAAjC,EAAAE,MACAC,QACA6B,eAIA,SAAAtB,EAAAX,EAAAC,GACA,GAAAA,EAAAE,MAAA+B,KAAA,CAEA,cAAAjC,EAAAE,MAAAO,KAAA,CAKA,IAJA,IAAA4B,EAAAtC,EAAAS,cAEA8B,GAAA,EAEApC,EAAAF,EAAAE,MAAqCA,EAAOA,IAAA+B,KAC5C,GAAAI,IAAAnC,EAAAG,OAAA,CACAiC,GAAA,EACA,MAIA,IAAAA,EACA,SAGA,KAAAtC,EAAAE,MAAA+B,MAAAjC,EAAAE,MAAAG,SAAAgC,GACArC,EAAAE,MAAAF,EAAAE,MAAA+B,KAGA,SAGA,OADAjC,EAAAE,MAAAF,EAAAE,MAAA+B,MACA,GAsDA,IAAAM,EAAA,CACAC,WAAA,SAAAC,GACA,OACA1B,SAAAjB,EACAI,MAAA,CACAG,OAAAoC,GAAA,EACAhC,KAAA,SACAwB,KAAA,KACA9B,OAAA,GAEAmB,MAAA,EACAZ,OAAA,IAGAgC,MAAA,SAAA3C,EAAAC,GACA,IAAA2C,EAAA,OAAA3C,EAAAE,MAAAC,OAAAH,EAAAE,MACAyC,GAAA5C,EAAAE,QAAA0C,EAAAxC,OAAA,GACA,IAAAyC,EAnEA,SAAA7C,EAAAC,GACA,IAAA4C,EAAA5C,EAAAe,SAAAhB,EAAAC,GACAqB,EAAAtB,EAAAsB,UAEA,WAAAA,IACArB,EAAAU,QAAA,KAGA,OAAAW,GAAA,OAAAA,IAAAtB,EAAA4B,OAAA,WAAAiB,IACAb,EAAAhC,EAAAC,GAGA,IAAA6C,EAAA,MAAgCC,QAAAzB,GAchC,IAZA,IAAAwB,GACAd,EAAAhC,EAAAC,EAAA,MAAkC+C,MAAAF,IAAA,IAGlCrD,EAAAwD,KAAA3B,IACAU,EAAAhC,EAAAC,GAGA,QAAAqB,GACAX,EAAAX,EAAAC,GAGA,WAAA4C,GACAlC,EAAAX,EAAAC,GACA,OAAAlB,EAMA,SAFA+D,EAAA,MAA4BC,QAAAzB,IAE5B,CACA,eAAArB,EAAAE,MAAAO,MAAAT,EAAAE,MAAA+B,MACAjC,EAAAE,MAAAF,EAAAE,MAAA+B,KAGAjC,EAAAE,MAAAO,MAAAY,IAAArB,EAAAE,MAAAF,EAAAE,MAAA+B,MAQA,OALAjC,EAAAU,QAAAX,EAAA4B,QACA,UAAA3B,EAAAE,MAAAO,MAAAT,EAAAE,MAAA+B,OAAAjC,EAAAE,MAAAF,EAAAE,MAAA+B,MACAjC,EAAAU,QAAA,GAGAkC,EAoBAK,CAAAlD,EAAAC,GAOA,OALA4C,GAAA,WAAAA,IACAD,MAAAxC,OAAA,GACAH,EAAAsB,KAAA,eAAAsB,GAAA,KAAA7C,EAAAsB,WAGAuB,GAEAb,OAAA,SAAA/B,EAAAkD,GACA,GAAAlD,EAAAe,UAAAjB,EAAA,SACA,IAAAI,EAAAF,EAAAE,MACAiD,EAAAD,GAAA,MAAiCJ,QAAAI,EAAAE,OAAA,OACjC,GAAAD,EAAA,eAAAjD,EAAAO,MAAAP,EAAA+B,MACA/B,IAAA+B,KAEA,IAAAoB,EAAAF,GAAAjD,EAAAO,OAAAyC,EAAAE,OAAA,GACA,OAAAlD,EAAAC,MAAAD,EAAA8B,aAAAqB,EAAA,MAAqEA,EAAAnD,EAAA+B,KAAA/B,GAAAG,QAErEiD,YAAA,IACAC,KAAA,UAEA,OAAAhB,IAIA7D,EAAA8E,WAAA,+CACA9E,EAAA8E,WAAA,sCACA9E,EAAA8E,WAAA,oCA/WAC,CAAQC,EAAQ","file":"static/js/15.c3c87901.chunk.js","sourcesContent":["// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/LICENSE\n\n/**\n * Link to the project's GitHub page:\n * https://github.com/pickhardt/coffeescript-codemirror-mode\n */\n(function (mod) {\n  if (typeof exports == \"object\" && typeof module == \"object\") // CommonJS\n    mod(require(\"../../lib/codemirror\"));else if (typeof define == \"function\" && define.amd) // AMD\n    define([\"../../lib/codemirror\"], mod);else // Plain browser env\n    mod(CodeMirror);\n})(function (CodeMirror) {\n  \"use strict\";\n\n  CodeMirror.defineMode(\"coffeescript\", function (conf, parserConf) {\n    var ERRORCLASS = \"error\";\n\n    function wordRegexp(words) {\n      return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n    }\n\n    var operators = /^(?:->|=>|\\+[+=]?|-[\\-=]?|\\*[\\*=]?|\\/[\\/=]?|[=!]=|<[><]?=?|>>?=?|%=?|&=?|\\|=?|\\^=?|\\~|!|\\?|(or|and|\\|\\||&&|\\?)=)/;\n    var delimiters = /^(?:[()\\[\\]{},:`=;]|\\.\\.?\\.?)/;\n    var identifiers = /^[_A-Za-z$][_A-Za-z$0-9]*/;\n    var atProp = /^@[_A-Za-z$][_A-Za-z$0-9]*/;\n    var wordOperators = wordRegexp([\"and\", \"or\", \"not\", \"is\", \"isnt\", \"in\", \"instanceof\", \"typeof\"]);\n    var indentKeywords = [\"for\", \"while\", \"loop\", \"if\", \"unless\", \"else\", \"switch\", \"try\", \"catch\", \"finally\", \"class\"];\n    var commonKeywords = [\"break\", \"by\", \"continue\", \"debugger\", \"delete\", \"do\", \"in\", \"of\", \"new\", \"return\", \"then\", \"this\", \"@\", \"throw\", \"when\", \"until\", \"extends\"];\n    var keywords = wordRegexp(indentKeywords.concat(commonKeywords));\n    indentKeywords = wordRegexp(indentKeywords);\n    var stringPrefixes = /^('{3}|\\\"{3}|['\\\"])/;\n    var regexPrefixes = /^(\\/{3}|\\/)/;\n    var commonConstants = [\"Infinity\", \"NaN\", \"undefined\", \"null\", \"true\", \"false\", \"on\", \"off\", \"yes\", \"no\"];\n    var constants = wordRegexp(commonConstants); // Tokenizers\n\n    function tokenBase(stream, state) {\n      // Handle scope changes\n      if (stream.sol()) {\n        if (state.scope.align === null) state.scope.align = false;\n        var scopeOffset = state.scope.offset;\n\n        if (stream.eatSpace()) {\n          var lineOffset = stream.indentation();\n\n          if (lineOffset > scopeOffset && state.scope.type == \"coffee\") {\n            return \"indent\";\n          } else if (lineOffset < scopeOffset) {\n            return \"dedent\";\n          }\n\n          return null;\n        } else {\n          if (scopeOffset > 0) {\n            dedent(stream, state);\n          }\n        }\n      }\n\n      if (stream.eatSpace()) {\n        return null;\n      }\n\n      var ch = stream.peek(); // Handle docco title comment (single line)\n\n      if (stream.match(\"####\")) {\n        stream.skipToEnd();\n        return \"comment\";\n      } // Handle multi line comments\n\n\n      if (stream.match(\"###\")) {\n        state.tokenize = longComment;\n        return state.tokenize(stream, state);\n      } // Single line comment\n\n\n      if (ch === \"#\") {\n        stream.skipToEnd();\n        return \"comment\";\n      } // Handle number literals\n\n\n      if (stream.match(/^-?[0-9\\.]/, false)) {\n        var floatLiteral = false; // Floats\n\n        if (stream.match(/^-?\\d*\\.\\d+(e[\\+\\-]?\\d+)?/i)) {\n          floatLiteral = true;\n        }\n\n        if (stream.match(/^-?\\d+\\.\\d*/)) {\n          floatLiteral = true;\n        }\n\n        if (stream.match(/^-?\\.\\d+/)) {\n          floatLiteral = true;\n        }\n\n        if (floatLiteral) {\n          // prevent from getting extra . on 1..\n          if (stream.peek() == \".\") {\n            stream.backUp(1);\n          }\n\n          return \"number\";\n        } // Integers\n\n\n        var intLiteral = false; // Hex\n\n        if (stream.match(/^-?0x[0-9a-f]+/i)) {\n          intLiteral = true;\n        } // Decimal\n\n\n        if (stream.match(/^-?[1-9]\\d*(e[\\+\\-]?\\d+)?/)) {\n          intLiteral = true;\n        } // Zero by itself with no other piece of number.\n\n\n        if (stream.match(/^-?0(?![\\dx])/i)) {\n          intLiteral = true;\n        }\n\n        if (intLiteral) {\n          return \"number\";\n        }\n      } // Handle strings\n\n\n      if (stream.match(stringPrefixes)) {\n        state.tokenize = tokenFactory(stream.current(), false, \"string\");\n        return state.tokenize(stream, state);\n      } // Handle regex literals\n\n\n      if (stream.match(regexPrefixes)) {\n        if (stream.current() != \"/\" || stream.match(/^.*\\//, false)) {\n          // prevent highlight of division\n          state.tokenize = tokenFactory(stream.current(), true, \"string-2\");\n          return state.tokenize(stream, state);\n        } else {\n          stream.backUp(1);\n        }\n      } // Handle operators and delimiters\n\n\n      if (stream.match(operators) || stream.match(wordOperators)) {\n        return \"operator\";\n      }\n\n      if (stream.match(delimiters)) {\n        return \"punctuation\";\n      }\n\n      if (stream.match(constants)) {\n        return \"atom\";\n      }\n\n      if (stream.match(atProp) || state.prop && stream.match(identifiers)) {\n        return \"property\";\n      }\n\n      if (stream.match(keywords)) {\n        return \"keyword\";\n      }\n\n      if (stream.match(identifiers)) {\n        return \"variable\";\n      } // Handle non-detected items\n\n\n      stream.next();\n      return ERRORCLASS;\n    }\n\n    function tokenFactory(delimiter, singleline, outclass) {\n      return function (stream, state) {\n        while (!stream.eol()) {\n          stream.eatWhile(/[^'\"\\/\\\\]/);\n\n          if (stream.eat(\"\\\\\")) {\n            stream.next();\n\n            if (singleline && stream.eol()) {\n              return outclass;\n            }\n          } else if (stream.match(delimiter)) {\n            state.tokenize = tokenBase;\n            return outclass;\n          } else {\n            stream.eat(/['\"\\/]/);\n          }\n        }\n\n        if (singleline) {\n          if (parserConf.singleLineStringErrors) {\n            outclass = ERRORCLASS;\n          } else {\n            state.tokenize = tokenBase;\n          }\n        }\n\n        return outclass;\n      };\n    }\n\n    function longComment(stream, state) {\n      while (!stream.eol()) {\n        stream.eatWhile(/[^#]/);\n\n        if (stream.match(\"###\")) {\n          state.tokenize = tokenBase;\n          break;\n        }\n\n        stream.eatWhile(\"#\");\n      }\n\n      return \"comment\";\n    }\n\n    function indent(stream, state, type) {\n      type = type || \"coffee\";\n      var offset = 0,\n          align = false,\n          alignOffset = null;\n\n      for (var scope = state.scope; scope; scope = scope.prev) {\n        if (scope.type === \"coffee\" || scope.type == \"}\") {\n          offset = scope.offset + conf.indentUnit;\n          break;\n        }\n      }\n\n      if (type !== \"coffee\") {\n        align = null;\n        alignOffset = stream.column() + stream.current().length;\n      } else if (state.scope.align) {\n        state.scope.align = false;\n      }\n\n      state.scope = {\n        offset: offset,\n        type: type,\n        prev: state.scope,\n        align: align,\n        alignOffset: alignOffset\n      };\n    }\n\n    function dedent(stream, state) {\n      if (!state.scope.prev) return;\n\n      if (state.scope.type === \"coffee\") {\n        var _indent = stream.indentation();\n\n        var matched = false;\n\n        for (var scope = state.scope; scope; scope = scope.prev) {\n          if (_indent === scope.offset) {\n            matched = true;\n            break;\n          }\n        }\n\n        if (!matched) {\n          return true;\n        }\n\n        while (state.scope.prev && state.scope.offset !== _indent) {\n          state.scope = state.scope.prev;\n        }\n\n        return false;\n      } else {\n        state.scope = state.scope.prev;\n        return false;\n      }\n    }\n\n    function tokenLexer(stream, state) {\n      var style = state.tokenize(stream, state);\n      var current = stream.current(); // Handle scope changes.\n\n      if (current === \"return\") {\n        state.dedent = true;\n      }\n\n      if ((current === \"->\" || current === \"=>\") && stream.eol() || style === \"indent\") {\n        indent(stream, state);\n      }\n\n      var delimiter_index = \"[({\".indexOf(current);\n\n      if (delimiter_index !== -1) {\n        indent(stream, state, \"])}\".slice(delimiter_index, delimiter_index + 1));\n      }\n\n      if (indentKeywords.exec(current)) {\n        indent(stream, state);\n      }\n\n      if (current == \"then\") {\n        dedent(stream, state);\n      }\n\n      if (style === \"dedent\") {\n        if (dedent(stream, state)) {\n          return ERRORCLASS;\n        }\n      }\n\n      delimiter_index = \"])}\".indexOf(current);\n\n      if (delimiter_index !== -1) {\n        while (state.scope.type == \"coffee\" && state.scope.prev) {\n          state.scope = state.scope.prev;\n        }\n\n        if (state.scope.type == current) state.scope = state.scope.prev;\n      }\n\n      if (state.dedent && stream.eol()) {\n        if (state.scope.type == \"coffee\" && state.scope.prev) state.scope = state.scope.prev;\n        state.dedent = false;\n      }\n\n      return style;\n    }\n\n    var external = {\n      startState: function startState(basecolumn) {\n        return {\n          tokenize: tokenBase,\n          scope: {\n            offset: basecolumn || 0,\n            type: \"coffee\",\n            prev: null,\n            align: false\n          },\n          prop: false,\n          dedent: 0\n        };\n      },\n      token: function token(stream, state) {\n        var fillAlign = state.scope.align === null && state.scope;\n        if (fillAlign && stream.sol()) fillAlign.align = false;\n        var style = tokenLexer(stream, state);\n\n        if (style && style != \"comment\") {\n          if (fillAlign) fillAlign.align = true;\n          state.prop = style == \"punctuation\" && stream.current() == \".\";\n        }\n\n        return style;\n      },\n      indent: function indent(state, text) {\n        if (state.tokenize != tokenBase) return 0;\n        var scope = state.scope;\n        var closer = text && \"])}\".indexOf(text.charAt(0)) > -1;\n        if (closer) while (scope.type == \"coffee\" && scope.prev) {\n          scope = scope.prev;\n        }\n        var closes = closer && scope.type === text.charAt(0);\n        if (scope.align) return scope.alignOffset - (closes ? 1 : 0);else return (closes ? scope.prev : scope).offset;\n      },\n      lineComment: \"#\",\n      fold: \"indent\"\n    };\n    return external;\n  }); // IANA registered media type\n  // https://www.iana.org/assignments/media-types/\n\n  CodeMirror.defineMIME(\"application/vnd.coffeescript\", \"coffeescript\");\n  CodeMirror.defineMIME(\"text/x-coffeescript\", \"coffeescript\");\n  CodeMirror.defineMIME(\"text/coffeescript\", \"coffeescript\");\n});"],"sourceRoot":""}