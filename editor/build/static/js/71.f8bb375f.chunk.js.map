{"version":3,"sources":["../node_modules/codemirror/mode/python/python.js"],"names":["CodeMirror","wordRegexp","words","RegExp","join","str","wordOperators","commonKeywords","commonBuiltins","top","state","scopes","length","registerHelper","concat","defineMode","conf","parserConf","ERRORCLASS","delimiters","singleDelimiters","operators","singleOperators","doubleOperators","doubleDelimiters","tripleDelimiters","i","splice","hangingIndent","indentUnit","myKeywords","myBuiltins","undefined","extra_keywords","extra_builtins","py3","version","Number","identifiers","stringPrefixes","keywords","builtins","tokenBase","stream","sol","lastToken","indent","indentation","type","scopeOffset","offset","eatSpace","lineOffset","pushPyScope","dedent","peek","errorToken","style","tokenBaseInner","match","floatLiteral","eat","intLiteral","isFmtString","current","toLowerCase","indexOf","tokenize","delimiter","tokenOuter","charAt","substr","singleline","OUTCLASS","tokenNestedExpr","depth","inner","tokenString","eol","eatWhile","next","singleLineStringErrors","isString","formatStringFactory","tokenStringFactory","pop","push","align","indented","tokenLexer","beginningOfLine","test","lambda","delimiter_index","column","pushBracketScope","slice","external","startState","basecolumn","token","addErr","textAfter","Pass","scope","closing","electricInput","closeBrackets","triples","lineComment","fold","defineMIME","name","split","mod","__webpack_require__"],"mappings":"8EAOC,SAAAA,GACD,aAEA,SAAAC,EAAAC,GACA,WAAAC,OAAA,MAAAD,EAAAE,KAAA,gBAGA,IA4VAC,EA5VAC,EAAAL,EAAA,yBACAM,EAAA,+LACAC,EAAA,+jBAGA,SAAAC,EAAAC,GACA,OAAAA,EAAAC,OAAAD,EAAAC,OAAAC,OAAA,GAHAZ,EAAAa,eAAA,qBAAAN,EAAAO,OAAAN,IAMAR,EAAAe,WAAA,kBAAAC,EAAAC,GAMA,IALA,IAAAC,EAAA,QACAC,EAAAF,EAAAE,YAAAF,EAAAG,kBAAA,4BAEAC,EAAA,CAAAJ,EAAAK,gBAAAL,EAAAM,gBAAAN,EAAAO,iBAAAP,EAAAQ,iBAAAR,EAAAI,WAAA,oDAEAK,EAAA,EAAmBA,EAAAL,EAAAT,OAAsBc,IACzCL,EAAAK,IAAAL,EAAAM,OAAAD,IAAA,GAGA,IAAAE,EAAAX,EAAAW,eAAAZ,EAAAa,WACAC,EAAAvB,EACAwB,EAAAvB,OACAwB,GAAAf,EAAAgB,iBAAAH,IAAAhB,OAAAG,EAAAgB,sBACAD,GAAAf,EAAAiB,iBAAAH,IAAAjB,OAAAG,EAAAiB,iBACA,IAAAC,IAAAlB,EAAAmB,SAAAC,OAAApB,EAAAmB,SAAA,GAEA,GAAAD,EAAA,CAEA,IAAAG,EAAArB,EAAAqB,aAAA,oDACAR,IAAAhB,OAAA,oDACAiB,IAAAjB,OAAA,kCACA,IAAAyB,EAAA,IAAApC,OAAA,2CAAuE,SAClE,CACL,IAAAmC,EAAArB,EAAAqB,aAAA,0BACAR,IAAAhB,OAAA,kBACAiB,IAAAjB,OAAA,kKACA,IAAAyB,EAAA,IAAApC,OAAA,2CAAuE,KAGvE,IAAAqC,EAAAvC,EAAA6B,GACAW,EAAAxC,EAAA8B,GAEA,SAAAW,EAAAC,EAAAjC,GACA,IAAAkC,EAAAD,EAAAC,OAAA,MAAAlC,EAAAmC,UAGA,GAFAD,IAAAlC,EAAAoC,OAAAH,EAAAI,eAEAH,GAAA,MAAAnC,EAAAC,GAAAsC,KAAA,CACA,IAAAC,EAAAxC,EAAAC,GAAAwC,OAEA,GAAAP,EAAAQ,WAAA,CACA,IAAAC,EAAAT,EAAAI,cAEA,OADAK,EAAAH,EAAAI,EAAA3C,GAA2D0C,EAAAH,GAAAK,EAAAX,EAAAjC,IAAA,KAAAiC,EAAAY,SAAA7C,EAAA8C,YAAA,GAC3D,KAEA,IAAAC,EAAAC,EAAAf,EAAAjC,GAEA,OADAuC,EAAA,GAAAK,EAAAX,EAAAjC,KAAA+C,GAAA,IAAAvC,GACAuC,EAIA,OAAAC,EAAAf,EAAAjC,GAGA,SAAAgD,EAAAf,EAAAjC,GACA,GAAAiC,EAAAQ,WAAA,YAEA,GAAAR,EAAAgB,MAAA,wBAEA,GAAAhB,EAAAgB,MAAA,gBACA,IAAAC,GAAA,EAcA,GAZAjB,EAAAgB,MAAA,iCACAC,GAAA,GAGAjB,EAAAgB,MAAA,kBACAC,GAAA,GAGAjB,EAAAgB,MAAA,YACAC,GAAA,GAGAA,EAGA,OADAjB,EAAAkB,IAAA,MACA,SAIA,IAAAC,GAAA,EAkBA,GAhBAnB,EAAAgB,MAAA,oBAAAG,GAAA,GAEAnB,EAAAgB,MAAA,gBAAAG,GAAA,GAEAnB,EAAAgB,MAAA,iBAAAG,GAAA,GAEAnB,EAAAgB,MAAA,mCAEAhB,EAAAkB,IAAA,MAEAC,GAAA,GAIAnB,EAAAgB,MAAA,kBAAAG,GAAA,GAEAA,EAGA,OADAnB,EAAAkB,IAAA,MACA,SAKA,GAAAlB,EAAAgB,MAAApB,GAAA,CACA,IAAAwB,GAAA,IAAApB,EAAAqB,UAAAC,cAAAC,QAAA,KAEA,OAAAH,GAIArD,EAAAyD,SAyBA,SAAAC,EAAAC,GACA,YAAAH,QAAAE,EAAAE,OAAA,GAAAL,gBAAA,GACAG,IAAAG,OAAA,GAGA,IAAAC,EAAA,GAAAJ,EAAAxD,OACA6D,EAAA,SAEA,SAAAC,EAAAC,GACA,gBAAAhC,EAAAjC,GACA,IAAAkE,EAAAlB,EAAAf,EAAAjC,GAUA,MARA,eAAAkE,IACA,KAAAjC,EAAAqB,UACAtD,EAAAyD,SAAAO,EAAAC,EAAA,GACa,KAAAhC,EAAAqB,YACbtD,EAAAyD,SAAAQ,EAAA,EAAAD,EAAAC,EAAA,GAAyEE,IAIzED,GAIA,SAAAC,EAAAlC,EAAAjC,GACA,MAAAiC,EAAAmC,OAGA,GAFAnC,EAAAoC,SAAA,eAEApC,EAAAkB,IAAA,OAEA,GADAlB,EAAAqC,OACAR,GAAA7B,EAAAmC,MAAA,OAAAL,MACW,IAAA9B,EAAAgB,MAAAS,GAEX,OADA1D,EAAAyD,SAAAE,EACAI,EACW,GAAA9B,EAAAgB,MAAA,MAEX,OAAAc,EACW,GAAA9B,EAAAgB,MAAA,KAAyB,GAGpC,OADAjD,EAAAyD,SAAAO,EAAA,GACA/B,EAAAqB,UAAAS,EAAkD/D,EAAAyD,SAAAxB,EAAAjC,GACvC,GAAAiC,EAAAgB,MAAA,MACX,OAAAc,EACW,GAAA9B,EAAAgB,MAAA,KAEX,OAAAzC,EAEAyB,EAAAkB,IAAA,QAIA,GAAAW,EAAA,CACA,GAAAvD,EAAAgE,uBAAA,OAAA/D,EAAmER,EAAAyD,SAAAE,EAGnE,OAAAI,EAIA,OADAI,EAAAK,UAAA,EACAL,EApFAM,CAAAxC,EAAAqB,UAAAtD,EAAAyD,UACAzD,EAAAyD,SAAAxB,EAAAjC,KAJAA,EAAAyD,SA0FA,SAAAC,EAAAC,GACA,YAAAH,QAAAE,EAAAE,OAAA,GAAAL,gBAAA,GACAG,IAAAG,OAAA,GAGA,IAAAC,EAAA,GAAAJ,EAAAxD,OACA6D,EAAA,SAEA,SAAAI,EAAAlC,EAAAjC,GACA,MAAAiC,EAAAmC,OAGA,GAFAnC,EAAAoC,SAAA,WAEApC,EAAAkB,IAAA,OAEA,GADAlB,EAAAqC,OACAR,GAAA7B,EAAAmC,MAAA,OAAAL,MACW,IAAA9B,EAAAgB,MAAAS,GAEX,OADA1D,EAAAyD,SAAAE,EACAI,EAEA9B,EAAAkB,IAAA,QAIA,GAAAW,EAAA,CACA,GAAAvD,EAAAgE,uBAAA,OAAA/D,EAAmER,EAAAyD,SAAAE,EAGnE,OAAAI,EAIA,OADAI,EAAAK,UAAA,EACAL,EAzHAO,CAAAzC,EAAAqB,UAAAtD,EAAAyD,UACAzD,EAAAyD,SAAAxB,EAAAjC,IAOA,QAAAgB,EAAA,EAAqBA,EAAAL,EAAAT,OAAsBc,IAC3C,GAAAiB,EAAAgB,MAAAtC,EAAAK,IAAA,iBAGA,OAAAiB,EAAAgB,MAAAxC,GAAA,cACA,KAAAT,EAAAmC,WAAAF,EAAAgB,MAAArB,GAAA,WACAK,EAAAgB,MAAAnB,IAAAG,EAAAgB,MAAArD,GAAA,UACAqC,EAAAgB,MAAAlB,GAAA,UACAE,EAAAgB,MAAA,8BAEAhB,EAAAgB,MAAArB,GACA,OAAA5B,EAAAmC,WAAA,SAAAnC,EAAAmC,UAAA,MACA,YAIAF,EAAAqC,OACA9D,GAmGA,SAAAmC,EAAA3C,GACA,WAAAD,EAAAC,GAAAsC,MACAtC,EAAAC,OAAA0E,MAGA3E,EAAAC,OAAA2E,KAAA,CACApC,OAAAzC,EAAAC,GAAAwC,OAAAlC,EAAAa,WACAmB,KAAA,KACAuC,MAAA,OAaA,SAAAjC,EAAAX,EAAAjC,GAGA,IAFA,IAAA8E,EAAA7C,EAAAI,cAEArC,EAAAC,OAAAC,OAAA,GAAAH,EAAAC,GAAAwC,OAAAsC,GAAA,CACA,SAAA/E,EAAAC,GAAAsC,KAAA,SACAtC,EAAAC,OAAA0E,MAGA,OAAA5E,EAAAC,GAAAwC,QAAAsC,EAGA,SAAAC,EAAA9C,EAAAjC,GACAiC,EAAAC,QAAAlC,EAAAgF,iBAAA,GACA,IAAAjC,EAAA/C,EAAAyD,SAAAxB,EAAAjC,GACAsD,EAAArB,EAAAqB,UAEA,GAAAtD,EAAAgF,iBAAA,KAAA1B,EAAA,OAAArB,EAAAgB,MAAArB,GAAA,UAAAH,EAAA,WAAAjB,EAQA,GAPA,KAAAyE,KAAA3B,KAAAtD,EAAAgF,iBAAA,GACA,YAAAjC,GAAA,WAAAA,GAAA,QAAA/C,EAAAmC,YAAAY,EAAA,QAEA,QAAAO,GAAA,UAAAA,IAAAtD,EAAA4C,QAAA,GACA,UAAAU,IAAAtD,EAAAkF,QAAA,GACA,KAAA5B,GAAAtD,EAAAkF,QAAA,MAAAnF,EAAAC,GAAAsC,MAAAK,EAAA3C,GAEA,GAAAsD,EAAApD,SAAA,iBAAA+E,KAAAlC,GAAA,CACA,IAAAoC,EAAA,MAAkC3B,QAAAF,GAIlC,IAHA,GAAA6B,GAnCA,SAAAlD,EAAAjC,EAAAsC,GACA,IAAAuC,EAAA5C,EAAAgB,MAAA,uBAAyC,QAAAhB,EAAAmD,SAAA,EACzCpF,EAAAC,OAAA2E,KAAA,CACApC,OAAAxC,EAAAoC,OAAAlB,EACAoB,OACAuC,UA8BAQ,CAAApD,EAAAjC,EAAA,MAAuEsF,MAAAH,IAAA,KAGvE,IAFAA,EAAA,MAA8B3B,QAAAF,IAE9B,CACA,GAAAvD,EAAAC,GAAAsC,MAAAgB,EAAmG,OAAA9C,EAAnGR,EAAAoC,OAAApC,EAAAC,OAAA0E,MAAAnC,OAAAtB,GASA,OALAlB,EAAA4C,OAAA,GAAAX,EAAAmC,OAAA,MAAArE,EAAAC,GAAAsC,OACAtC,EAAAC,OAAAC,OAAA,GAAAF,EAAAC,OAAA0E,MACA3E,EAAA4C,QAAA,GAGAG,EAGA,IAAAwC,EAAA,CACAC,WAAA,SAAAC,GACA,OACAhC,SAAAzB,EACA/B,OAAA,EACAuC,OAAAiD,GAAA,EACAnD,KAAA,KACAuC,MAAA,OAEAzC,OAAAqD,GAAA,EACAtD,UAAA,KACA+C,QAAA,EACAtC,OAAA,IAGA8C,MAAA,SAAAzD,EAAAjC,GACA,IAAA2F,EAAA3F,EAAA8C,WACA6C,IAAA3F,EAAA8C,YAAA,GACA,IAAAC,EAAAgC,EAAA9C,EAAAjC,GAIA,OAHA+C,GAAA,WAAAA,IAAA/C,EAAAmC,UAAA,WAAAY,GAAA,eAAAA,EAAAd,EAAAqB,UAAAP,GACA,eAAAA,MAAA,MACAd,EAAAmC,OAAApE,EAAAkF,SAAAlF,EAAAkF,QAAA,GACAS,EAAA5C,EAAA,IAAAvC,EAAAuC,GAEAX,OAAA,SAAApC,EAAA4F,GACA,GAAA5F,EAAAyD,UAAAzB,EAAA,OAAAhC,EAAAyD,SAAAe,SAAAlF,EAAAuG,KAAA,EACA,IAAAC,EAAA/F,EAAAC,GACA+F,EAAAD,EAAAxD,MAAAsD,EAAAhC,OAAA,GACA,aAAAkC,EAAAjB,MAAAiB,EAAAjB,OAAAkB,EAAA,KAAwED,EAAAtD,QAAAuD,EAAA7E,EAAA,IAExE8E,cAAA,gBACAC,cAAA,CACAC,QAAA,OAEAC,YAAA,IACAC,KAAA,UAEA,OAAAb,IAEAjG,EAAA+G,WAAA,0BAMA/G,EAAA+G,WAAA,iBACAC,KAAA,SACA/E,gBANA5B,EAMA,6HALAA,EAAA4G,MAAA,QAvWAC,CAAQC,EAAQ","file":"static/js/71.f8bb375f.chunk.js","sourcesContent":["// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/LICENSE\n(function (mod) {\n  if (typeof exports == \"object\" && typeof module == \"object\") // CommonJS\n    mod(require(\"../../lib/codemirror\"));else if (typeof define == \"function\" && define.amd) // AMD\n    define([\"../../lib/codemirror\"], mod);else // Plain browser env\n    mod(CodeMirror);\n})(function (CodeMirror) {\n  \"use strict\";\n\n  function wordRegexp(words) {\n    return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n  }\n\n  var wordOperators = wordRegexp([\"and\", \"or\", \"not\", \"is\"]);\n  var commonKeywords = [\"as\", \"assert\", \"break\", \"class\", \"continue\", \"def\", \"del\", \"elif\", \"else\", \"except\", \"finally\", \"for\", \"from\", \"global\", \"if\", \"import\", \"lambda\", \"pass\", \"raise\", \"return\", \"try\", \"while\", \"with\", \"yield\", \"in\"];\n  var commonBuiltins = [\"abs\", \"all\", \"any\", \"bin\", \"bool\", \"bytearray\", \"callable\", \"chr\", \"classmethod\", \"compile\", \"complex\", \"delattr\", \"dict\", \"dir\", \"divmod\", \"enumerate\", \"eval\", \"filter\", \"float\", \"format\", \"frozenset\", \"getattr\", \"globals\", \"hasattr\", \"hash\", \"help\", \"hex\", \"id\", \"input\", \"int\", \"isinstance\", \"issubclass\", \"iter\", \"len\", \"list\", \"locals\", \"map\", \"max\", \"memoryview\", \"min\", \"next\", \"object\", \"oct\", \"open\", \"ord\", \"pow\", \"property\", \"range\", \"repr\", \"reversed\", \"round\", \"set\", \"setattr\", \"slice\", \"sorted\", \"staticmethod\", \"str\", \"sum\", \"super\", \"tuple\", \"type\", \"vars\", \"zip\", \"__import__\", \"NotImplemented\", \"Ellipsis\", \"__debug__\"];\n  CodeMirror.registerHelper(\"hintWords\", \"python\", commonKeywords.concat(commonBuiltins));\n\n  function top(state) {\n    return state.scopes[state.scopes.length - 1];\n  }\n\n  CodeMirror.defineMode(\"python\", function (conf, parserConf) {\n    var ERRORCLASS = \"error\";\n    var delimiters = parserConf.delimiters || parserConf.singleDelimiters || /^[\\(\\)\\[\\]\\{\\}@,:`=;\\.\\\\]/; //               (Backwards-compatiblity with old, cumbersome config system)\n\n    var operators = [parserConf.singleOperators, parserConf.doubleOperators, parserConf.doubleDelimiters, parserConf.tripleDelimiters, parserConf.operators || /^([-+*/%\\/&|^]=?|[<>=]+|\\/\\/=?|\\*\\*=?|!=|[~!@])/];\n\n    for (var i = 0; i < operators.length; i++) {\n      if (!operators[i]) operators.splice(i--, 1);\n    }\n\n    var hangingIndent = parserConf.hangingIndent || conf.indentUnit;\n    var myKeywords = commonKeywords,\n        myBuiltins = commonBuiltins;\n    if (parserConf.extra_keywords != undefined) myKeywords = myKeywords.concat(parserConf.extra_keywords);\n    if (parserConf.extra_builtins != undefined) myBuiltins = myBuiltins.concat(parserConf.extra_builtins);\n    var py3 = !(parserConf.version && Number(parserConf.version) < 3);\n\n    if (py3) {\n      // since http://legacy.python.org/dev/peps/pep-0465/ @ is also an operator\n      var identifiers = parserConf.identifiers || /^[_A-Za-z\\u00A1-\\uFFFF][_A-Za-z0-9\\u00A1-\\uFFFF]*/;\n      myKeywords = myKeywords.concat([\"nonlocal\", \"False\", \"True\", \"None\", \"async\", \"await\"]);\n      myBuiltins = myBuiltins.concat([\"ascii\", \"bytes\", \"exec\", \"print\"]);\n      var stringPrefixes = new RegExp(\"^(([rbuf]|(br)|(fr))?('{3}|\\\"{3}|['\\\"]))\", \"i\");\n    } else {\n      var identifiers = parserConf.identifiers || /^[_A-Za-z][_A-Za-z0-9]*/;\n      myKeywords = myKeywords.concat([\"exec\", \"print\"]);\n      myBuiltins = myBuiltins.concat([\"apply\", \"basestring\", \"buffer\", \"cmp\", \"coerce\", \"execfile\", \"file\", \"intern\", \"long\", \"raw_input\", \"reduce\", \"reload\", \"unichr\", \"unicode\", \"xrange\", \"False\", \"True\", \"None\"]);\n      var stringPrefixes = new RegExp(\"^(([rubf]|(ur)|(br))?('{3}|\\\"{3}|['\\\"]))\", \"i\");\n    }\n\n    var keywords = wordRegexp(myKeywords);\n    var builtins = wordRegexp(myBuiltins); // tokenizers\n\n    function tokenBase(stream, state) {\n      var sol = stream.sol() && state.lastToken != \"\\\\\";\n      if (sol) state.indent = stream.indentation(); // Handle scope changes\n\n      if (sol && top(state).type == \"py\") {\n        var scopeOffset = top(state).offset;\n\n        if (stream.eatSpace()) {\n          var lineOffset = stream.indentation();\n          if (lineOffset > scopeOffset) pushPyScope(state);else if (lineOffset < scopeOffset && dedent(stream, state) && stream.peek() != \"#\") state.errorToken = true;\n          return null;\n        } else {\n          var style = tokenBaseInner(stream, state);\n          if (scopeOffset > 0 && dedent(stream, state)) style += \" \" + ERRORCLASS;\n          return style;\n        }\n      }\n\n      return tokenBaseInner(stream, state);\n    }\n\n    function tokenBaseInner(stream, state) {\n      if (stream.eatSpace()) return null; // Handle Comments\n\n      if (stream.match(/^#.*/)) return \"comment\"; // Handle Number Literals\n\n      if (stream.match(/^[0-9\\.]/, false)) {\n        var floatLiteral = false; // Floats\n\n        if (stream.match(/^[\\d_]*\\.\\d+(e[\\+\\-]?\\d+)?/i)) {\n          floatLiteral = true;\n        }\n\n        if (stream.match(/^[\\d_]+\\.\\d*/)) {\n          floatLiteral = true;\n        }\n\n        if (stream.match(/^\\.\\d+/)) {\n          floatLiteral = true;\n        }\n\n        if (floatLiteral) {\n          // Float literals may be \"imaginary\"\n          stream.eat(/J/i);\n          return \"number\";\n        } // Integers\n\n\n        var intLiteral = false; // Hex\n\n        if (stream.match(/^0x[0-9a-f_]+/i)) intLiteral = true; // Binary\n\n        if (stream.match(/^0b[01_]+/i)) intLiteral = true; // Octal\n\n        if (stream.match(/^0o[0-7_]+/i)) intLiteral = true; // Decimal\n\n        if (stream.match(/^[1-9][\\d_]*(e[\\+\\-]?[\\d_]+)?/)) {\n          // Decimal literals may be \"imaginary\"\n          stream.eat(/J/i); // TODO - Can you have imaginary longs?\n\n          intLiteral = true;\n        } // Zero by itself with no other piece of number.\n\n\n        if (stream.match(/^0(?![\\dx])/i)) intLiteral = true;\n\n        if (intLiteral) {\n          // Integer literals may be \"long\"\n          stream.eat(/L/i);\n          return \"number\";\n        }\n      } // Handle Strings\n\n\n      if (stream.match(stringPrefixes)) {\n        var isFmtString = stream.current().toLowerCase().indexOf('f') !== -1;\n\n        if (!isFmtString) {\n          state.tokenize = tokenStringFactory(stream.current(), state.tokenize);\n          return state.tokenize(stream, state);\n        } else {\n          state.tokenize = formatStringFactory(stream.current(), state.tokenize);\n          return state.tokenize(stream, state);\n        }\n      }\n\n      for (var i = 0; i < operators.length; i++) {\n        if (stream.match(operators[i])) return \"operator\";\n      }\n\n      if (stream.match(delimiters)) return \"punctuation\";\n      if (state.lastToken == \".\" && stream.match(identifiers)) return \"property\";\n      if (stream.match(keywords) || stream.match(wordOperators)) return \"keyword\";\n      if (stream.match(builtins)) return \"builtin\";\n      if (stream.match(/^(self|cls)\\b/)) return \"variable-2\";\n\n      if (stream.match(identifiers)) {\n        if (state.lastToken == \"def\" || state.lastToken == \"class\") return \"def\";\n        return \"variable\";\n      } // Handle non-detected items\n\n\n      stream.next();\n      return ERRORCLASS;\n    }\n\n    function formatStringFactory(delimiter, tokenOuter) {\n      while (\"rubf\".indexOf(delimiter.charAt(0).toLowerCase()) >= 0) {\n        delimiter = delimiter.substr(1);\n      }\n\n      var singleline = delimiter.length == 1;\n      var OUTCLASS = \"string\";\n\n      function tokenNestedExpr(depth) {\n        return function (stream, state) {\n          var inner = tokenBaseInner(stream, state);\n\n          if (inner == \"punctuation\") {\n            if (stream.current() == \"{\") {\n              state.tokenize = tokenNestedExpr(depth + 1);\n            } else if (stream.current() == \"}\") {\n              if (depth > 1) state.tokenize = tokenNestedExpr(depth - 1);else state.tokenize = tokenString;\n            }\n          }\n\n          return inner;\n        };\n      }\n\n      function tokenString(stream, state) {\n        while (!stream.eol()) {\n          stream.eatWhile(/[^'\"\\{\\}\\\\]/);\n\n          if (stream.eat(\"\\\\\")) {\n            stream.next();\n            if (singleline && stream.eol()) return OUTCLASS;\n          } else if (stream.match(delimiter)) {\n            state.tokenize = tokenOuter;\n            return OUTCLASS;\n          } else if (stream.match('{{')) {\n            // ignore {{ in f-str\n            return OUTCLASS;\n          } else if (stream.match('{', false)) {\n            // switch to nested mode\n            state.tokenize = tokenNestedExpr(0);\n            if (stream.current()) return OUTCLASS;else return state.tokenize(stream, state);\n          } else if (stream.match('}}')) {\n            return OUTCLASS;\n          } else if (stream.match('}')) {\n            // single } in f-string is an error\n            return ERRORCLASS;\n          } else {\n            stream.eat(/['\"]/);\n          }\n        }\n\n        if (singleline) {\n          if (parserConf.singleLineStringErrors) return ERRORCLASS;else state.tokenize = tokenOuter;\n        }\n\n        return OUTCLASS;\n      }\n\n      tokenString.isString = true;\n      return tokenString;\n    }\n\n    function tokenStringFactory(delimiter, tokenOuter) {\n      while (\"rubf\".indexOf(delimiter.charAt(0).toLowerCase()) >= 0) {\n        delimiter = delimiter.substr(1);\n      }\n\n      var singleline = delimiter.length == 1;\n      var OUTCLASS = \"string\";\n\n      function tokenString(stream, state) {\n        while (!stream.eol()) {\n          stream.eatWhile(/[^'\"\\\\]/);\n\n          if (stream.eat(\"\\\\\")) {\n            stream.next();\n            if (singleline && stream.eol()) return OUTCLASS;\n          } else if (stream.match(delimiter)) {\n            state.tokenize = tokenOuter;\n            return OUTCLASS;\n          } else {\n            stream.eat(/['\"]/);\n          }\n        }\n\n        if (singleline) {\n          if (parserConf.singleLineStringErrors) return ERRORCLASS;else state.tokenize = tokenOuter;\n        }\n\n        return OUTCLASS;\n      }\n\n      tokenString.isString = true;\n      return tokenString;\n    }\n\n    function pushPyScope(state) {\n      while (top(state).type != \"py\") {\n        state.scopes.pop();\n      }\n\n      state.scopes.push({\n        offset: top(state).offset + conf.indentUnit,\n        type: \"py\",\n        align: null\n      });\n    }\n\n    function pushBracketScope(stream, state, type) {\n      var align = stream.match(/^([\\s\\[\\{\\(]|#.*)*$/, false) ? null : stream.column() + 1;\n      state.scopes.push({\n        offset: state.indent + hangingIndent,\n        type: type,\n        align: align\n      });\n    }\n\n    function dedent(stream, state) {\n      var indented = stream.indentation();\n\n      while (state.scopes.length > 1 && top(state).offset > indented) {\n        if (top(state).type != \"py\") return true;\n        state.scopes.pop();\n      }\n\n      return top(state).offset != indented;\n    }\n\n    function tokenLexer(stream, state) {\n      if (stream.sol()) state.beginningOfLine = true;\n      var style = state.tokenize(stream, state);\n      var current = stream.current(); // Handle decorators\n\n      if (state.beginningOfLine && current == \"@\") return stream.match(identifiers, false) ? \"meta\" : py3 ? \"operator\" : ERRORCLASS;\n      if (/\\S/.test(current)) state.beginningOfLine = false;\n      if ((style == \"variable\" || style == \"builtin\") && state.lastToken == \"meta\") style = \"meta\"; // Handle scope changes.\n\n      if (current == \"pass\" || current == \"return\") state.dedent += 1;\n      if (current == \"lambda\") state.lambda = true;\n      if (current == \":\" && !state.lambda && top(state).type == \"py\") pushPyScope(state);\n\n      if (current.length == 1 && !/string|comment/.test(style)) {\n        var delimiter_index = \"[({\".indexOf(current);\n        if (delimiter_index != -1) pushBracketScope(stream, state, \"])}\".slice(delimiter_index, delimiter_index + 1));\n        delimiter_index = \"])}\".indexOf(current);\n\n        if (delimiter_index != -1) {\n          if (top(state).type == current) state.indent = state.scopes.pop().offset - hangingIndent;else return ERRORCLASS;\n        }\n      }\n\n      if (state.dedent > 0 && stream.eol() && top(state).type == \"py\") {\n        if (state.scopes.length > 1) state.scopes.pop();\n        state.dedent -= 1;\n      }\n\n      return style;\n    }\n\n    var external = {\n      startState: function startState(basecolumn) {\n        return {\n          tokenize: tokenBase,\n          scopes: [{\n            offset: basecolumn || 0,\n            type: \"py\",\n            align: null\n          }],\n          indent: basecolumn || 0,\n          lastToken: null,\n          lambda: false,\n          dedent: 0\n        };\n      },\n      token: function token(stream, state) {\n        var addErr = state.errorToken;\n        if (addErr) state.errorToken = false;\n        var style = tokenLexer(stream, state);\n        if (style && style != \"comment\") state.lastToken = style == \"keyword\" || style == \"punctuation\" ? stream.current() : style;\n        if (style == \"punctuation\") style = null;\n        if (stream.eol() && state.lambda) state.lambda = false;\n        return addErr ? style + \" \" + ERRORCLASS : style;\n      },\n      indent: function indent(state, textAfter) {\n        if (state.tokenize != tokenBase) return state.tokenize.isString ? CodeMirror.Pass : 0;\n        var scope = top(state),\n            closing = scope.type == textAfter.charAt(0);\n        if (scope.align != null) return scope.align - (closing ? 1 : 0);else return scope.offset - (closing ? hangingIndent : 0);\n      },\n      electricInput: /^\\s*[\\}\\]\\)]$/,\n      closeBrackets: {\n        triples: \"'\\\"\"\n      },\n      lineComment: \"#\",\n      fold: \"indent\"\n    };\n    return external;\n  });\n  CodeMirror.defineMIME(\"text/x-python\", \"python\");\n\n  var words = function words(str) {\n    return str.split(\" \");\n  };\n\n  CodeMirror.defineMIME(\"text/x-cython\", {\n    name: \"python\",\n    extra_keywords: words(\"by cdef cimport cpdef ctypedef enum except \" + \"extern gil include nogil property public \" + \"readonly struct union DEF IF ELIF ELSE\")\n  });\n});"],"sourceRoot":""}